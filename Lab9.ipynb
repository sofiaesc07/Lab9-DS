{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias generales\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.util import ngrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- Dash ---\n",
    "import dash\n",
    "from dash import Dash, html, dcc, callback, Output, Input\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# --- Analisis de sentimientos ---\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar keyword y location en un solo campo\n",
    "data['features'] = data['keyword'].fillna('') + ' ' + data['location'].fillna('') + ' ' + data['text']\n",
    "\n",
    "# Convertir a minúsculas\n",
    "data['text'] = data['text'].str.lower()\n",
    "\n",
    "# Quitar caracteres especiales, URL y números\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "data['text'] = data['text'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "# Quitar stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###frecuencia de las palabras\n",
    "# Dividir los datos en tweets de desastres y no desastres\n",
    "disaster_tweets = data[data['target'] == 1]['text']\n",
    "non_disaster_tweets = data[data['target'] == 0]['text']\n",
    "\n",
    "# Tokenización y conteo de palabras\n",
    "disaster_word_counts = Counter(' '.join(disaster_tweets).split())\n",
    "non_disaster_word_counts = Counter(' '.join(non_disaster_tweets).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            deeds reason earthquake may allah forgive us\n",
       "1                   forest fire near la ronge sask canada\n",
       "2       residents asked shelter place notified officer...\n",
       "3       people receive wildfires evacuation orders cal...\n",
       "4       got sent photo ruby alaska smoke wildfires pou...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding bridge collapse nearb...\n",
       "7609    ariaahrary thetawniest control wild fires cali...\n",
       "7610                                 utckm volcano hawaii\n",
       "7611    police investigating ebike collided car little...\n",
       "7612    latest homes razed northern california wildfir...\n",
       "Name: text, Length: 3271, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palabras más comunes en tweets de desastres\n",
    "disaster_common_words = disaster_word_counts.most_common(20)\n",
    "# Palabras más comunes en tweets no desastres\n",
    "non_disaster_common_words = non_disaster_word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vectorizador para unigramas y bigramas\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=1000000)  \n",
    "\n",
    "# Obtener la matriz de términos de documento\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Obtener las palabras más comunes en unigramas y bigramas para cada clase\n",
    "disaster_common_words = vectorizer.get_feature_names_out()\n",
    "non_disaster_common_words = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nube de palabras de desastres\n",
    "wordcloud_disaster = WordCloud(width=800, height=400, background_color='white', colormap='Reds').generate_from_frequencies(disaster_word_counts)\n",
    "# Nube de palabras para tweets no desastres\n",
    "wordcloud_non_disaster = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate_from_frequencies(non_disaster_word_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet_length'] = data['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = set(disaster_word_counts.keys()) & set(non_disaster_word_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el analizador de sentimiento\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calcular los valores de sentimiento para cada texto en tus datos\n",
    "sentimiento = np.zeros(len(data['text']))\n",
    "for k in range(len(data['text'])):\n",
    "    sentimiento[k] = sia.polarity_scores(data['text'][k]).get('compound')\n",
    "\n",
    "data['sentimiento'] = sentimiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6992    check want twister tickets vip experience see ...\n",
      "3382    batfanuk enjoyed show today great fun emergenc...\n",
      "3163    batfanuk enjoyed show today great fun emergenc...\n",
      "6292    todays storm pass let tomorrows light greet ki...\n",
      "7182    roguewatson nothing wrong lethal weapon series...\n",
      "2238    meditationbymsg ppl got method meditation ampg...\n",
      "7449    wounds kissed someone doesnt see disasters sou...\n",
      "6295    free ebay sniping rt lumbar extender back stre...\n",
      "6560    duchovbutt starbuckscully madmakny davidduchov...\n",
      "1856                  love love love remember first crush\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Top 10 tweets mas positivos segun sentimiento.\n",
    "print(data.sort_values(by='sentimiento', ascending=False).head(10)['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la negatividad para cada tweet y agregarla al DataFrame\n",
    "negatividad = []\n",
    "for text in data['text']:\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    negatividad.append(sentiment_scores['neg'])\n",
    "\n",
    "data['negatividad'] = negatividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media del sentimiento para los tweets de desastre y no desastre\n",
    "disaster_sentiment_mean = data[data['target'] == 1]['sentimiento'].mean()\n",
    "non_disaster_sentiment_mean = data[data['target'] == 0]['sentimiento'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la cantidad de tweets clasificados como desastres y no desastres\n",
    "disaster_tweets = sum(data['target'] == 1)\n",
    "non_disaster_tweets = sum(data['target'] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['text', 'negatividad']], data['target'], random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo con TF-IDF y Naive Bayes\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  # Puedes ajustar el número máximo de características\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Crear el modelo con TF-IDF y SVM\n",
    "text_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  \n",
    "    ('clf', SVC(kernel='linear')),\n",
    "])\n",
    "\n",
    "# Crear el modelo con TF-IDF y Random Forest Classifier\n",
    "text_rf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  \n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar los modelos\n",
    "text_clf.fit(X_train['text'], y_train)\n",
    "text_svm.fit(X_train['text'], y_train)\n",
    "text_rf.fit(X_train['text'], y_train)\n",
    "\n",
    "# Evaluar los modelos\n",
    "y_pred = text_clf.predict(X_test['text'])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_svm = text_svm.predict(X_test['text'])\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "y_pred_rf = text_rf.predict(X_test['text'])\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##funcion para clasificar\n",
    "def classify_tweet(tweet):\n",
    "    prediction = text_clf.predict([tweet])\n",
    "    if prediction[0] == 1:\n",
    "        return \"Desastre\"\n",
    "    else:\n",
    "        return \"No desastre\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciamos el Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar la aplicación Dash\n",
    "app = dash.Dash(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir el layout de la aplicación\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Clasificador de Tweets\"),\n",
    "    html.H2(\"Explora los datos\"),\n",
    "    dcc.Dropdown(\n",
    "        id='data-dropdown',\n",
    "        options=[\n",
    "            {'label': 'Tweets de desastres', 'value': 'disaster'},\n",
    "            {'label': 'Tweets no desastres', 'value': 'non_disaster'}\n",
    "        ],\n",
    "        value='disaster'\n",
    "    ),\n",
    "    dcc.Graph(id='data-graph'),\n",
    "    \n",
    "    # Nube de palabras\n",
    "    html.Div([\n",
    "        html.H2(\"Nube de Palabras\"),\n",
    "        dcc.Dropdown(\n",
    "            id='wordcloud-dropdown',\n",
    "            options=[\n",
    "                {'label': 'Tweets de desastres', 'value': 'disaster'},\n",
    "                {'label': 'Tweets no desastres', 'value': 'non_disaster'}\n",
    "            ],\n",
    "            value='disaster'\n",
    "        ),\n",
    "        dcc.Graph(id='wordcloud-graph'),\n",
    "    ]),\n",
    "    \n",
    "    # Histograma de la longitud de Tweets\n",
    "    html.Div([\n",
    "        html.H2(\"Distribución de Longitud de Tweets\"),\n",
    "        dcc.Graph(\n",
    "            figure={\n",
    "                'data': [\n",
    "                    {\n",
    "                        'x': data[data['target'] == 1]['tweet_length'],\n",
    "                        'type': 'histogram',\n",
    "                        'name': 'Desastre',\n",
    "                        'opacity': 0.7,\n",
    "                        'marker': {'color': 'tomato'}\n",
    "                    },\n",
    "                    {\n",
    "                        'x': data[data['target'] == 0]['tweet_length'],\n",
    "                        'type': 'histogram',\n",
    "                        'name': 'No Desastre',\n",
    "                        'opacity': 0.7,\n",
    "                        'marker': {'color': 'teal'}\n",
    "                    }\n",
    "                ],\n",
    "                'layout': {\n",
    "                    'xaxis': {'title': \"Longitud del Tweet\"},\n",
    "                    'yaxis': {'title': \"Frecuencia\"},\n",
    "                    'bargap': 0.2,\n",
    "                    'bargroupgap': 0.1,\n",
    "                    \"title\": \"Distribución de Longitud de Tweets\"\n",
    "                }\n",
    "            },\n",
    "            style={'width': \"100%\"}\n",
    "        ),\n",
    "    ]),\n",
    "    \n",
    "    # Gráfico de pie para la clasificación de tweets\n",
    "    html.Div([\n",
    "        html.H2(\"Distribución de Clasificación de Tweets\"),\n",
    "        dcc.Graph(\n",
    "            figure={\n",
    "                \"data\": [\n",
    "                    {\n",
    "                        \"labels\": [\"Desastre\", \"No Desastre\"],\n",
    "                        \"values\": [disaster_tweets, non_disaster_tweets],\n",
    "                        \"type\": \"pie\",\n",
    "                        \"name\": \"Clasificación\",\n",
    "                        \"marker\": {\"colors\": [\"tomato\", \"teal\"]},\n",
    "                        \"textinfo\": \"label+percent\",\n",
    "                        \"insidetextorientation\": \"radial\"\n",
    "                    }\n",
    "                ],\n",
    "                \"layout\": {\n",
    "                    \"title\": {\"text\": \"Distribución de Clasificación de Tweets\"}\n",
    "                }\n",
    "            },\n",
    "            style={'width': \"100%\"}\n",
    "        ),\n",
    "    ]),\n",
    "\n",
    "        # Gráfico de barras para la media del sentimiento\n",
    "    html.Div([\n",
    "        html.H2(\"Media del Sentimiento\"),\n",
    "        dcc.Graph(\n",
    "            id='sentiment-mean-graph',\n",
    "            figure={\n",
    "                'data': [\n",
    "                    {\n",
    "                        'x': ['Desastre', 'No Desastre'],\n",
    "                        'y': [disaster_sentiment_mean, non_disaster_sentiment_mean],\n",
    "                        'type': 'bar',\n",
    "                        'name': 'Media del Sentimiento',\n",
    "                        'marker': {'color': ['tomato', 'teal']}\n",
    "                    }\n",
    "                ],\n",
    "                'layout': {\n",
    "                    'xaxis': {'title': \"Tipo de Tweet\"},\n",
    "                    'yaxis': {'title': \"Media del Sentimiento\"},\n",
    "                    \"title\": \"Media del Sentimiento para Tweets de Desastre y No Desastre\"\n",
    "                }\n",
    "            },\n",
    "            style={'width': \"100%\"}\n",
    "        ),\n",
    "    ]),\n",
    "    \n",
    "    # Clasificación de tweets\n",
    "    html.Div([\n",
    "        html.H2(\"Selecciona un modelo para la clasificación\"),\n",
    "        dcc.Dropdown(\n",
    "            id='model-dropdown',\n",
    "            options=[\n",
    "                {'label': \"Naive Bayes\", \"value\": \"nb\"},\n",
    "                {'label': \"SVM\", \"value\": \"svm\"},\n",
    "                {'label': \"Random Forest\", \"value\": \"rf\"}\n",
    "            ],\n",
    "            value=\"nb\"\n",
    "        ),\n",
    "        dcc.Input(id=\"tweet-input\", type=\"text\", placeholder=\"Introduce un tweet para clasificar\"),\n",
    "        html.Button(\"Clasificar\", id=\"classify-button\", n_clicks=0),\n",
    "        html.Div(id=\"classification-output\")\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la función de callback para la exploración de datos\n",
    "@app.callback(\n",
    "    Output('data-graph', 'figure'),\n",
    "    [Input('data-dropdown', 'value')]\n",
    ")\n",
    "\n",
    "def update_graph(value):\n",
    "    if value == 'disaster':\n",
    "        word_counts = disaster_word_counts\n",
    "        title = 'Palabras más comunes en tweets de desastres'\n",
    "        color = 'tomato'  # Color para los tweets de desastres\n",
    "    else:\n",
    "        word_counts = non_disaster_word_counts\n",
    "        title = 'Palabras más comunes en tweets no desastres'\n",
    "        color = 'teal'  # Color para los tweets no desastres\n",
    "\n",
    "    data = go.Bar(\n",
    "        x=list(word_counts.keys()),\n",
    "        y=list(word_counts.values()),\n",
    "        marker_color=color  # Aplicar el color seleccionado\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        xaxis=dict(title='Palabras'),\n",
    "        yaxis=dict(title='Frecuencia')\n",
    "    )\n",
    "\n",
    "    return go.Figure(data=data, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la función de callback para la nube de palabras\n",
    "@app.callback(\n",
    "    Output('wordcloud-graph', \"figure\"),\n",
    "    [Input('wordcloud-dropdown', \"value\")]\n",
    ")\n",
    "def update_wordcloud(value):\n",
    "    if value == \"disaster\":\n",
    "        img = wordcloud_disaster.to_image()\n",
    "    else:\n",
    "        img = wordcloud_non_disaster.to_image()\n",
    "\n",
    "    fig = px.imshow(img)\n",
    "    fig.update_layout(margin=dict(l=20, r=20, t=30, b=20))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la función de callback para la clasificación de tweets\n",
    "@app.callback(\n",
    "    Output('classification-output', 'children'),\n",
    "    [Input('classify-button', 'n_clicks')],\n",
    "    [State('tweet-input', 'value'), State('model-dropdown', 'value')]\n",
    ")\n",
    "def classify_tweet(n_clicks, tweet, model):\n",
    "    if n_clicks > 0:\n",
    "        if model == 'nb':\n",
    "            prediction = text_clf.predict([tweet])\n",
    "        elif model == 'svm':\n",
    "            prediction = text_svm.predict([tweet])\n",
    "        elif model == 'rf':\n",
    "            prediction = text_rf.predict([tweet])\n",
    "        \n",
    "        return f\"{'Desastre' if prediction[0] == 1 else 'No desastre'}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13b06bdd510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejecutar la aplicación\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
